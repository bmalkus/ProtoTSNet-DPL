{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bmk/ProtoTSNetDPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmk/miniconda3/envs/dpl/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n",
      "/home/bmk/miniconda3/envs/dpl/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ~/ProtoTSNetDPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from deepproblog.dataset import Dataset as DPLDataset, DataLoader\n",
    "from deepproblog.query import Query\n",
    "from deepproblog.network import Network\n",
    "from deepproblog.model import Model\n",
    "from deepproblog.engines import ExactEngine\n",
    "from deepproblog.train import train_model\n",
    "from deepproblog.evaluate import get_confusion_matrix, get_fact_accuracy\n",
    "from problog.logic import Term, Constant, list2term\n",
    "\n",
    "from model import ProtoTSNet\n",
    "from autoencoder import RegularConvEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class ArtificialProtosDataset():\n",
    "    def __init__(self, N, feature_noise_power=0.1, randomize_right_side=False):\n",
    "        self.data = []\n",
    "        x = np.linspace(0, 100, 100)\n",
    "        for _ in range(N):\n",
    "            label = np.random.randint(0, 2)\n",
    "            ts = np.zeros((3, 100))\n",
    "            if label == 0:\n",
    "                ts[0, :40] = signal.sawtooth(x[:40] / (1+1))\n",
    "                ts[1, :40] = signal.square(x[:40] / (2+1))\n",
    "            else:\n",
    "                ts[0, :40] = signal.square(x[:40] / (1+1))\n",
    "                ts[1, :40] = signal.sawtooth(x[:40] / (2+1))\n",
    "            if np.random.choice([0, 1]) == 0:\n",
    "                ts[2, :40] = signal.square(np.random.choice([-1, 1]) * x[:40] / 3)\n",
    "            else:\n",
    "                ts[2, :40] = signal.sawtooth(np.random.choice([-1, 1]) * x[:40] / 3)\n",
    "            for i in range(3):\n",
    "                if randomize_right_side:\n",
    "                    ts[i, 40:] = np.sin(x[40:] / (np.random.randint(0, 4)+i+1)) / 3\n",
    "                else:\n",
    "                    ts[i, 40:] = np.sin(x[40:] / (i+1)) / 3\n",
    "                ts[i, :] += np.random.normal(0, feature_noise_power, 100)\n",
    "            self.data.append((ts.astype('float32'), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[int(idx[0])][0])\n",
    "    \n",
    "    def get_label(self, idx):\n",
    "        return self.data[idx][1]\n",
    "\n",
    "class ArtificialProtosQueries(DPLDataset):\n",
    "    def __init__(self, dataset: ArtificialProtosDataset, phase: str):\n",
    "        self.phase = phase\n",
    "        self.dataset = dataset\n",
    "        self.dataset_len = len(dataset)\n",
    "        self.num_classes = 2 # len(set([dataset.get_label(i) for i in range(self.dataset_len)]))\n",
    "\n",
    "    # def to_query(self, i: int) -> Query:\n",
    "    #     ds_entry = i\n",
    "    #     correct_cls = self.dataset.get_label(ds_entry)\n",
    "\n",
    "    #     ts_term = Term(f'ts{i}')\n",
    "    #     q = Query(\n",
    "    #         Term(\n",
    "    #             'is_class',\n",
    "    #             ts_term,\n",
    "    #             Term(f'c{correct_cls}')\n",
    "    #         ),\n",
    "    #         {\n",
    "    #             ts_term: Term(\n",
    "    #                 \"tensor\",\n",
    "    #                 Term(\n",
    "    #                     self.phase,\n",
    "    #                     Constant(ds_entry),\n",
    "    #                 ),\n",
    "    #             )\n",
    "    #         }\n",
    "    #     )\n",
    "    #     return q\n",
    "\n",
    "    # def __len__(self):\n",
    "    #     return self.dataset_len\n",
    "\n",
    "    def to_query(self, i: int) -> Query:\n",
    "        \n",
    "        ds_entry = i // self.num_classes\n",
    "        cls_num = i % self.num_classes\n",
    "        correct_cls = self.dataset.get_label(ds_entry)\n",
    "\n",
    "        ts_term = Term(f'ts{i}')\n",
    "        q = Query(\n",
    "            Term(\n",
    "                'is_class',\n",
    "                ts_term,\n",
    "                Term(f'c{cls_num}')\n",
    "            ),\n",
    "            {\n",
    "                ts_term: Term(\n",
    "                    \"tensor\",\n",
    "                    Term(\n",
    "                        self.phase,\n",
    "                        Constant(ds_entry),\n",
    "                    ),\n",
    "                )\n",
    "            },\n",
    "            p = float(cls_num == correct_cls)\n",
    "        )\n",
    "        return q\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len * self.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing ProtoTSNet...\n",
      "Loading logic file...\n"
     ]
    }
   ],
   "source": [
    "protos_per_class = 1\n",
    "latent_features = 32\n",
    "\n",
    "print('Preparing ProtoTSNet...')\n",
    "autoencoder = RegularConvEncoder(num_features=3, latent_features=latent_features, padding='same')\n",
    "encoder = autoencoder.encoder\n",
    "net = ProtoTSNet(\n",
    "    cnn_base=encoder,\n",
    "    for_deepproblog=True,\n",
    "    num_features=3,\n",
    "    ts_sample_len=100,\n",
    "    prototype_shape=(protos_per_class*2, latent_features, 20),\n",
    "    num_classes=2,\n",
    "    prototype_activation_function='log'\n",
    ")\n",
    "\n",
    "dpl_net = Network(net, \"ptsnet\", batching=False)\n",
    "dpl_net.optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "print('Loading logic file...')\n",
    "model = Model(\"proto_logic.pl\", [dpl_net])\n",
    "model.set_engine(ExactEngine(model))\n",
    "# model.set_engine(ApproximateEngine(model, 1, ApproximateEngine.geometric_mean, exploration=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state('./snapshots/initial_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = ArtificialProtosDataset(50)\n",
    "model.add_tensor_source(\"test\", test_dataset)\n",
    "test_queries = ArtificialProtosQueries(test_dataset, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = model.networks['ptsnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<deepproblog.network.Network at 0x7f63d3189ba0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{is_class(tensor(test(2)),c0): tensor(0.5649, grad_fn=<SelectBackward0>)}]\n",
      "[{is_class(tensor(test(2)),c1): tensor(0.5194, grad_fn=<SelectBackward0>)}]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(model.solve([test_queries.to_query(2*idx)]))\n",
    "print(model.solve([test_queries.to_query(2*idx+1)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepProbLog kernel",
   "language": "python",
   "name": "dpl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
